"""This module encapsulates the interface to OpenFST. This is the only
module with dependency to OpenFST. To enable python support in OpenFST,
use a recent version (>=1.5.2) and compile with --enable_python. 
Further information can be found here:

http://www.openfst.org/twiki/bin/view/FST/PythonExtension 

This file includes the fst, nfst, and rtn predictors.

Note: If we ise arc weights in FSTs, we multiply them by -1 as 
everything in SGNMT is logprob, not -logprob as in FSTs log 
or tropical semirings. You can disable this behavior with --fst_to_log

Note2: The FSTs and RTNs are assumed to have both <S> and </S>. This 
has compatibility reasons, as lattices generated by HiFST have these
symbols.
"""

import pywrapfst as fst
import glob
import logging
import os
import sys
import copy
from subprocess import call
from shutil import copyfile

from cam.sgnmt import utils
from cam.sgnmt.decoding.core import Predictor


"""OpenFST's reserved ID for epsilon arcs. """
EPS_ID = 0


NEG_INF = float("-inf")

"""Temporary file name to use if a FST file is zipped. """
TMP_FILENAME = '/tmp/sgnmt.%s.fst' % os.getpid()


def load_fst(path):
    """Loads a FST from the file system using PyFSTs ``read()`` method.
    GZipped format is also supported. The arc type must be standard
    or log, otherwise PyFST cannot load them.
    
    Args:
        path (string):  Path to the FST file to load
    Returns:
        fst. PyFST FST object or ``None`` if FST could not be read
    """
    try:
        if path[-3:].lower() == ".gz":
            copyfile(path, "%s.gz" % TMP_FILENAME)
            call(["gunzip", "%s.gz" % TMP_FILENAME])
            ret = fst.Fst.read(TMP_FILENAME)
            os.remove(TMP_FILENAME)
        else: # Fst not zipped
            ret = fst.Fst.read(path)
        logging.debug("Read fst from %s" % path)
        return ret
    except:
        logging.error("Error reading fst from %s: %s" %
            (path, sys.exc_info()[1]))
    return None


class FstPredictor(Predictor):
    """This predictor can read determinized translation lattices. The
    predictor state consists of the current node. This is unique as the
    lattices are determinized.
    """
    
    def __init__(self,
                 fst_path,
                 use_weights,
                 normalize_scores,
                 add_bos_to_eos_score = False,
                 to_log = True):
        """Creates a new fst predictor.
        
        Args:
            fst_path (string): Path to the FST file
            use_weights (bool): If false, replace all arc weights with
                                0 (=log 1).
            normalize_scores (bool): If true, we normalize the weights
                                     on all outgoing arcs such that
                                     they sum up to 1
            add_bos_to_eos_score (bool): Add the score at the <S> arc
                                         to the </S> arc. This results
                                         in scores consistent with 
                                         OpenFST's replace operation,
                                         as <S> scores are normally
                                         ignored by SGNMT.
            to_log (bool): SGNMT uses normal log probs (scores) while
                           arc weights in FSTs normally have cost (i.e.
                           neg. log values) semantics. Therefore, if
                           true, we multiply arc weights by -1.
        """
        super(FstPredictor, self).__init__()
        self.fst_path = fst_path
        self.weight_factor = -1.0 if to_log else 1.0
        self.use_weights = use_weights
        self.normalize_scores = normalize_scores
        self.cur_fst = None
        self.add_bos_to_eos_score = add_bos_to_eos_score
        self.cur_node = -1
        
    def get_unk_probability(self, posterior):
        """Always returns negative infinity: Words outside the 
        translation lattice are not possible according to this
        predictor.
        
        Returns:
            float. Negative infinity
        """
        return NEG_INF 
    
    def predict_next(self):
        """Uses the outgoing arcs from the current node to build up the
        scores for the next word.
        
        Returns:
            dict. Set of words on outgoing arcs from the current node
            together with their scores, or an empty set if we currently
            have no active node or fst.
        """
        if not self.cur_node:
            return {}
        scores = {arc.olabel: self.weight_factor*float(arc.weight)
                for arc in self.cur_fst.arcs(self.cur_node)}
        if utils.EOS_ID in scores and self.add_bos_to_eos_score:
            scores[utils.EOS_ID] += self.bos_score
        return self.finalize_posterior(scores,
                self.use_weights, self.normalize_scores)
    
    def initialize(self, src_sentence):
        """Loads the FST from the file system and consumes the start
        of sentence symbol. 
        
        Args:
            src_sentence (list):  Not used
        """
        self.cur_fst = load_fst(self.fst_path % (self.current_sen_id+1))
        self.cur_node = self.cur_fst.start if self.cur_fst else None
        self.bos_score = self.consume(utils.GO_ID)
        if not self.bos_score: # Override None
            self.bos_score = 0.0
    
    def consume(self, word):
        """Updates the current node by following the arc labelled with
        ``word``. If there is no such arc, we set ``cur_node`` to -1,
        indicating that the predictor is in an invalid state. In this
        case, all subsequent ``predict_next`` calls will return the
        empty set.
        
        Args:
            word (int): Word on an outgoing arc from the current node
        
        Returns:
            float. Weight on the traversed arc
        """
        if self.cur_node < 0:
            return
        from_state = self.cur_node
        self.cur_node = None
        for arc in self.cur_fst.arcs(from_state):
            if arc.olabel == word:
                self.cur_node = arc.nextstate
                return self.weight_factor*float(arc.weight)
    
    def get_state(self):
        """Returns the current node. """
        return self.cur_node
    
    def set_state(self, state):
        """Sets the current node. """
        self.cur_node = state

    def reset(self):
        """Resets the loaded FST object and current node. """
        self.cur_fst = None
        self.cur_node = None
    
    def initialize_heuristic(self, src_sentence):
        """Creates a matrix of shortest distances between nodes. """
        # TODO: Update to use OpenFST instead of PyFST
        self.distances = self.cur_fst.shortest_distance(reverse=True)
    
    def estimate_future_cost(self, hypo):
        """The FST predictor comes with its own heuristic function. We
        use the shortest path in the fst as future cost estimator. """
        if not self.cur_node:
            return 0.0
        last_word = hypo.trgt_sentence[-1]
        for arc in self.cur_fst.arcs(self.cur_node):
            if arc.olabel == last_word:
                return float(self.distances[arc.nextstate])
        return 0.0


class NondeterministicFstPredictor(Predictor):
    """This predictor can handle non-deterministic translation 
    lattices. In contrast to the fst predictor for deterministic
    lattices, we store a set of nodes which are all reachable from
    the start node through the current history.
    """
    
    def __init__(self, fst_path, use_weights, normalize_scores, to_log = True):
        """Creates a new nfst predictor.
        
        Args:
            fst_path (string): Path to the FST file
            use_weights (bool): If false, replace all arc weights with
                                0 (=log 1).
            normalize_scores (bool): If true, we normalize the weights
                                     on all outgoing arcs such that
                                     they sum up to 1
            to_log (bool): SGNMT uses normal log probs (scores) while
                           arc weights in FSTs normally have cost (i.e.
                           neg. log values) semantics. Therefore, if
                           true, we multiply arc weights by -1.
        """
        super(NondeterministicFstPredictor, self).__init__()
        self.fst_path = fst_path
        self.weight_factor = -1.0 if to_log else 1.0
        self.use_weights = use_weights
        self.normalize_scores = normalize_scores
        self.cur_fst = None
        self.cur_nodes = []
        
    def get_unk_probability(self, posterior):
        """Always returns negative infinity: Words outside the 
        translation lattice are not possible according to this
        predictor.
        
        Returns:
            float. Negative infinity
        """
        return NEG_INF 
    
    def predict_next(self):
        """Uses the outgoing arcs from all current node to build up the
        scores for the next word. This method does not follow epsilon
        arcs: ``consume`` updates ``cur_nodes`` such that all reachable
        arcs with word ids are connected directly with a node in
        ``cur_nodes``. If there are multiple arcs with the same word,
        we use the log sum of the arc weights as score.
        
        Returns:
            dict. Set of words on outgoing arcs from the current node
            together with their scores, or an empty set if we currently
            have no active nodes or fst.
        """
        scorelst = {}
        for weight,node in self.cur_nodes:
            for arc in self.cur_fst.arcs(node): 
                if arc.olabel != EPS_ID:
                    scorelst[arc.olabel] = scorelst.get(arc.olabel, []) + [
                                        weight
                                        + self.weight_factor*float(arc.weight)] 
        scores = {word: utils.log_sum(weights) 
                    for word,weights in scorelst.iteritems()}
        return self.finalize_posterior(scores,
                self.use_weights, self.normalize_scores)
    
    def initialize(self, src_sentence):
        """Loads the FST from the file system and consumes the start
        of sentence symbol. 
        
        Args:
            src_sentence (list):  Not used
        """
        self.cur_fst = load_fst(self.fst_path % (self.current_sen_id+1))
        self.cur_nodes = [(0.0, self.cur_fst.start)] if self.cur_fst else []
        self.consume(utils.GO_ID)
    
    def consume(self, word):
        """Updates the current nodes by searching for all nodes which
        are reachable from the current nodes by a path consisting of 
        any number of epsilons and exactly one ``word`` label. If there
        is no such arc, we set the predictor in an invalid state. In 
        this case, all subsequent ``predict_next`` calls will return 
        the empty set.
        
        Args:
            word (int): Word on an outgoing arc from the current node
        """
        # Add all epsilon reachable states
        d = {}
        # Collect distances to nodes reachable by word
        for weight,node in self.cur_nodes:
            for arc in self.cur_fst.arcs(node):
                if arc.olabel == word:
                    d[arc.nextstate] = d.get(arc.nextstate, []) + [
                                        weight
                                        + self.weight_factor*float(arc.weight)]
        # Add epsilon reachable states
        prev_d = {}
        while len(prev_d) != len(d):
            prev_d = copy.copy(d)
            for node,weights in prev_d.iteritems():
                for arc in self.cur_fst.arcs(node):
                    weight = utils.log_sum(weights)
                    if arc.olabel == EPS_ID:
                        d[arc.nextstate] = d.get(arc.nextstate, []) + [
                                        weight
                                        + self.weight_factor*float(arc.weight)]
        self.cur_nodes = [(utils.log_sum(weights), n) 
                            for n,weights in d.iteritems()]
    
    def get_state(self):
        """Returns the set of current nodes """
        return self.cur_nodes
    
    def set_state(self, state):
        """Sets the set of current nodes """
        self.cur_nodes = state

    def reset(self):
        """Resets the FST and empties the set of current nodes """ 
        self.cur_fst = None
        self.cur_nodes = []
    
    def initialize_heuristic(self, src_sentence):
        """Creates a matrix of shortest distances between all nodes """
        # TODO: Update to use OpenFST instead of PyFST
        self.distances = self.cur_fst.shortest_distance(reverse=True)
    
    def estimate_future_cost(self, hypo):
        """The FST predictor comes with its own heuristic function. We
        use the shortest path in the fst as future cost estimator. """
        last_word = hypo.trgt_sentence[-1]
        dists = []
        for n in self.cur_nodes:
            for arc in self.cur_fst[n].arcs:
                if arc.olabel == last_word:
                    dists.append(float(self.distances[arc.nextstate]))
                    break
        return 0.0 if not dists else min(dists)


class RtnPredictor(Predictor):
    """Predictor for RTNs (recurrent transition networks). This 
    predictor assumes a directory structure as produced by HiFST. You 
    can use this predictor for non-deterministic lattices too. This
    implementation supports late expansion: RTNs are only expanded as
    far as necessary to retrieve all currently reachable states.
    
    ``cur_nodes`` contains the accumulated weights from the last 
    consumed word (if ambiguous, the largest)
    
    This implementation does not maintain a list of active nodes like 
    the other automata predictors. Instead, we store the current 
    history and search for the active nodes at each expansion. This is
    more expensive, but fstreplace might change state IDs so a list of
    active nodes might get corrupted.
    
    Note that this predictor does not support FSTs in gzip format.
    """
    
    def __init__(self,
                 rtn_path,
                 use_weights,
                 normalize_scores,
                 to_log = True,
                 minimize_rtns = False,
                 rmeps = True):
        """Creates a new RTN predictor.
        
        Args:
            rtn_path (string): Path to the RTN directory
            use_weights (bool): If false, replace all arc weights with
                                0 (=log 1).
            normalize_scores (bool): If true, we normalize the weights
                                     on all outgoing arcs such that
                                     they sum up to 1
            to_log (bool): SGNMT uses normal log probs (scores) while
                           arc weights in FSTs normally have cost (i.e.
                           neg. log values) semantics. Therefore, if
                           true, we multiply arc weights by -1.
            minimize_rtns (bool): Minimize the FST after each replace
                                  operation
            rmeps (bool): Remove epsilons in the FST after each replace
                          operation 
        """
        super(RtnPredictor, self).__init__()
        self.root_path = rtn_path
        self.minimize_rtns = minimize_rtns
        self.rmeps = rmeps
        self.use_weights = use_weights
        self.normalize_scores = normalize_scores
        self.weight_factor = -1.0 if to_log else 1.0
        self.cur_fst = None # current root fst
        start_id = '1'
        try:
            with open("%s/ntmap" % self.root_path) as f:
                ntmap = dict(line.strip().split(None, 1) for line in f)
                start_id = ntmap['S']
        except:
            logging.warn("Could not find NT S in ntmap. Assuming its ID 1")
        self.root_fst_prefix = "1%s000" % start_id.zfill(3)
        
    def get_unk_probability(self, posterior):
        """Always returns negative infinity: Words outside the 
        RTN are not possible according to this predictor.
        
        Returns:
            float. Negative infinity
        """
        return NEG_INF
    
    def initialize(self, src_sentence):
        """Loads the root RTN and consumes the start of sentence 
        symbol.
        
        Args:
            src_sentence (list):  Not used
        """
        try:
            file_name = "%s/%d.fst" % (self.root_path, self.current_sen_id+1)
            if not os.access(file_name, os.R_OK): # Find root FST
                search_pattern = '%s/%d/%s*.fst' % (self.root_path,
                                                    self.current_sen_id+1,
                                                    self.root_fst_prefix)
                candidates = glob.glob(search_pattern)
                if not candidates:
                    logging.error("Could not find root fst in %s" % 
                                    search_pattern)
                if len(candidates) > 1:
                    logging.warn("Ambiguous root fst for %s. Take the one "
                                 "with largest span." % search_pattern)
                    candidates = sorted(candidates)
                file_name = candidates[-1]
            self.cur_fst = fst.Fst.read(file_name) 
            logging.debug("Read (root)fst from %s" % file_name)
        except:
            logging.error("Error reading fst from %s: %s" %
                (file_name, sys.exc_info()[1]))
            self.cur_fst = None
        self.cur_history = []
        self.sub_fsts = {}
        self.consume(utils.GO_ID)
    
    def expand_rtn(self, func):
        """This method expands the RTN as far as necessary. This means
        that the RTN is expanded s.t. we can build the posterior for 
        ``cur_history``. In practice, this means that we follow all 
        epsilon edges and replaces all NT edges until all paths with 
        the prefix ``cur_history`` in the RTN have at least one more 
        terminal token. Then, we apply ``func`` to all reachable nodes.
        """
        # TODO: Update this to make it work with OpenFST instead of PyFST
        updated = True
        while updated:
            updated = False
            label_fst_map = {}
            self.visited_nodes = {}
            self.cur_fst.arc_sort_output()
            self.add_to_label_fst_map_recursive(label_fst_map,
                                                {},
                                                self.cur_fst.start, 
                                                0.0,
                                                self.cur_history, func)
            if label_fst_map:
                logging.debug("Replace %d NT arcs for history %s" % (
                                                            len(label_fst_map),
                                                            self.cur_history))
                # This requires fiddling around with osyms because pyfst uses
                # it for some stupid reason but fst._fst.read doesn't create 
                # even a null-object implementation
                self.cur_fst.osyms = fst.SymbolTable()
                for label in label_fst_map:
                    self.cur_fst.osyms[label] = int(label)
                self.cur_fst.osyms['__ROOT__'] = len(label_fst_map) + 2000000000
                self.cur_fst.isyms = self.cur_fst.osyms
                replaced_fst = self.cur_fst.replace(label_fst_map, True)
                self.cur_fst = replaced_fst
                self.cur_fst.osyms = None
                self.cur_fst.isyms = None
                updated = True
        if self.rmeps or self.minimize_rtns:
            self.cur_fst.remove_epsilon()
        if self.minimize_rtns:
            tmp = self.cur_fst.determinize()
            self.cur_fst = tmp
            self.cur_fst.minimize()
    
    def add_to_label_fst_map_recursive(self, 
                                       label_fst_map, 
                                       visited_nodes, 
                                       root_node, 
                                       acc_weight, 
                                       history, 
                                       func):
        """Adds arcs to ``label_fst_map`` if they are labeled with an
        NT symbol and reachable from ``root_node`` via ``history``.
          
        Note: visited_nodes is maintained for each history separately
        """
        # TODO: Update this to make it work with OpenFST instead of PyFST
        if root_node in visited_nodes:
            # This introduces some error as we take the score of the first best
            # path with a certain history, not the globally best path. For now,
            # this error should not be significant
            return
        visited_nodes[root_node] = True
        try:
            arcs = self.cur_fst[root_node].arcs
        except:
            logging.debug("invalid state id %d" % root_node)
            return
        for arc in arcs:
            arc_acc_weight = acc_weight + self.weight_factor*float(arc.weight)
            if arc.olabel == EPS_ID: # Follow epsilon edges
                self.add_to_label_fst_map_recursive(label_fst_map,
                                                    visited_nodes,
                                                    arc.nextstate,
                                                    arc_acc_weight, 
                                                    history,
                                                    func)
            elif not history:
                if self.is_nt_label(arc.olabel): # Add to label_fst_map
                    replace_label = len(label_fst_map) + 2000000000
                    label_fst_map[str(replace_label)] = self.get_sub_fst(
                                                                    arc.olabel)
                    arc.ilabel = replace_label
                    arc.olabel = replace_label
                else: # This is a regular arc and we have no history left
                    func(arc.nextstate, arc.olabel, arc_acc_weight) # apply func
            elif arc.olabel == history[0]: # history is not empty
                self.add_to_label_fst_map_recursive(label_fst_map,
                                                    {},
                                                    arc.nextstate,
                                                    arc_acc_weight,
                                                    history[1:],
                                                    func)
            elif arc.olabel > history[0]: # FST is arc sorted, we can stop here
                break
        
    
    def is_nt_label(self, label):
        """Returns true if ``label`` is a non-terminal. """
        s = str(label)
        return len(s) == 10 and s[0] == '1'

    def get_sub_fst(self, fst_id):
        """ Load sub fst from the file system or the cache """
        if fst_id in self.sub_fsts:
            return self.sub_fsts[fst_id]
        sub_fst_path = "%s/%d/%d.fst" %  (self.root_path,
                                          self.current_sen_id+1,
                                          fst_id)
        try:
            sub_fst = fst.Fst.read(sub_fst_path)
            logging.debug("Read sub fst from %s" % sub_fst_path)
            self.sub_fsts[fst_id] = sub_fst
            return sub_fst
        except:
            logging.error("Could not load sub fst %s" % sub_fst_path)
        
    def _add_to_cur_posterior(self, node, label, weight):
        """Can be used as ``func`` argument in ``expand_rtn`` to build
        up the posterior for the next target token  in ``predict_next``
        """
        self.cur_posterior[label] = max(self.cur_posterior.get(label, NEG_INF),
                                        weight)
    
    def predict_next(self):
        """Expands RTN as far as possible and uses the outgoing edges 
        from nodes reachable by the current history to build up
        the posterior for the next word. If there are no such nodes
        or arcs, or no root FST is loaded, return the empty set.
        """
        if not self.cur_fst:
            return {}
        self.cur_posterior = {}
        self.expand_rtn(self._add_to_cur_posterior)
        return self.finalize_posterior(self.cur_posterior,
                                       self.use_weights,
                                       self.normalize_scores)
    
    def consume(self, word):
        """Adds ``word`` to the current history. """
        self.cur_history.append(word)
    
    def get_state(self):
        """Returns the current history. """
        return self.cur_history
    
    def set_state(self, state):
        """Sets the current history. """
        self.cur_history = state

    def reset(self):
        """Unloads the current RTN """ 
        self.cur_fst = None

